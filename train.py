import torch
import torch.optim as optim
from torch.utils.data import DataLoader
from dataset import SuperResolutionDataset
from model import Generator, Discriminator
import os
import torchvision.transforms as transforms

# ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
epochs = 10  # å­¦ç¿’å›æ•°
batch_size = 28  # ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆGPUã®ãƒ¡ãƒ¢ãƒªã«ä¾å­˜ï¼‰
lr_g = 1e-4  # Generatorã®å­¦ç¿’ç‡
lr_d = 1e-6  # Discriminatorã®å­¦ç¿’ç‡

# ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®å®šç¾©ï¼ˆãƒ©ãƒ³ãƒ€ãƒ åè»¢ï¼‰
transform = transforms.Compose([
    transforms.RandomHorizontalFlip(),  # ãƒ©ãƒ³ãƒ€ãƒ ã«æ°´å¹³åè»¢
    transforms.RandomVerticalFlip(),    # ãƒ©ãƒ³ãƒ€ãƒ ã«å‚ç›´åè»¢
    transforms.ToTensor(),              # ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
])

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆ
dataset = SuperResolutionDataset(low_res_dir="data/low", high_res_dir="data/high", transform=transform)
dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

# ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
generator = Generator().cuda()
discriminator = Discriminator(img_size=512).cuda()

# ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã®è¨­å®š
optim_g = optim.Adam(generator.parameters(), lr=lr_g, betas=(0.9, 0.999))
optim_d = optim.Adam(discriminator.parameters(), lr=lr_d, betas=(0.9, 0.999))

# æå¤±é–¢æ•°
criterion = torch.nn.MSELoss()  # Adversarial Loss

# é€”ä¸­ã‹ã‚‰å†é–‹ã™ã‚‹ãŸã‚ã®å¤‰æ•°
start_epoch = 1  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯1ã‹ã‚‰é–‹å§‹

# ã‚‚ã—ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚Œã°ã€èª­ã¿è¾¼ã‚€
checkpoint_path = "checkpoint/checkpoint.pth"
if os.path.exists(checkpoint_path):
    checkpoint = torch.load(checkpoint_path)
    generator.load_state_dict(checkpoint["generator_state_dict"])
    discriminator.load_state_dict(checkpoint["discriminator_state_dict"])
    optim_g.load_state_dict(checkpoint["optimizer_g_state_dict"])
    optim_d.load_state_dict(checkpoint["optimizer_d_state_dict"])
    start_epoch = checkpoint["epoch"] + 1  # æ¬¡ã®ã‚¨ãƒãƒƒã‚¯ã‹ã‚‰é–‹å§‹
    print(f"âœ… å­¦ç¿’ã‚’ {start_epoch} ã‚¨ãƒãƒƒã‚¯ç›®ã‹ã‚‰å†é–‹ã—ã¾ã™ã€‚")
else:
    print("ğŸš€ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚‚å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚‚è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ–°è¦å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™ã€‚")

# å­¦ç¿’ãƒ«ãƒ¼ãƒ—
for epoch in range(start_epoch, epochs + 1):
    for batch_idx, (lr, hr) in enumerate(dataloader):
        # ãƒ‡ãƒ¼ã‚¿ã‚’GPUã«é€ã‚‹
        lr, hr = lr.cuda(), hr.cuda()

        # # ãƒã‚¤ã‚ºã‚’åŠ ãˆã‚‹
        # noise = torch.randn_like(lr) * 0.1  # 0.1å€ã®ãƒã‚¤ã‚º
        # lr_noisy = lr + noise  # ä½è§£åƒåº¦ç”»åƒã«ãƒã‚¤ã‚ºã‚’åŠ ãˆã‚‹

        # å…ƒç”»åƒã®æœ€å°å€¤ã¨æœ€å¤§å€¤ã‚’è¨ˆç®—
        lr_min, lr_max = lr.min(), lr.max()

        # ãƒã‚¤ã‚ºå¼·åº¦ã‚’å‹•çš„ã«èª¿æ•´ï¼ˆç”»åƒç¯„å›²ã«åˆã‚ã›ã¦ï¼‰
        noise_strength = 0.1 * (1.0 - (lr_max - lr_min))  # ç¯„å›²ã«å¿œã˜ãŸãƒã‚¤ã‚ºå¼·åº¦èª¿æ•´

        # ã‚¬ã‚¦ã‚¹ãƒã‚¤ã‚ºã‚’åŠ ãˆã€æœ€å¤§å€¤ã‚’è¶…ãˆãªã„ã‚ˆã†ã«èª¿æ•´
        noise = torch.randn_like(lr) * noise_strength
        lr_noisy = lr + noise

        # ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ã—ãªã„ã§ã€æœ€å°å€¤ã¨æœ€å¤§å€¤ã‚’å…ƒã«æˆ»ã™
        lr_noisy = torch.clamp(lr_noisy, 0.0, 1.0)

        # -----------------
        # Discriminatorã®è¨“ç·´
        # -----------------
        optim_d.zero_grad()

        # æœ¬ç‰©ã®ç”»åƒã¨ç”Ÿæˆã•ã‚ŒãŸç”»åƒ
        real_output = discriminator(hr)
        fake_hr = generator(lr_noisy)
        fake_output = discriminator(fake_hr.detach())  # å­¦ç¿’ã‚’ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã—ãªã„

        # æœ¬ç‰©ã¨å½ç‰©ã®åˆ¤å®šæå¤±
        real_loss = criterion(real_output, torch.ones_like(real_output))
        fake_loss = criterion(fake_output, torch.zeros_like(fake_output))
        d_loss = (real_loss + fake_loss) / 2
        d_loss.backward()
        optim_d.step()

        # -----------------
        # Generatorã®è¨“ç·´
        # -----------------
        optim_g.zero_grad()

        # Generatorã®å‡ºåŠ›ã‚’Discriminatorã«é€šã—ã¦ã€æå¤±ã‚’è¨ˆç®—
        fake_output = discriminator(fake_hr)
        g_loss = criterion(fake_output, torch.ones_like(fake_output))  # æœ¬ç‰©ã¨èªè­˜ã•ã›ã‚‹

        g_loss.backward()
        optim_g.step()

        if batch_idx % 10 == 0:
            print(f"Epoch [{epoch}/{epochs}], Step [{batch_idx}/{len(dataloader)}], D Loss: {d_loss.item()}, G Loss: {g_loss.item()}")
    
    # 5ã‚¨ãƒãƒƒã‚¯ã”ã¨ã«ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
    if epoch % 5 == 0:
        torch.save(generator.state_dict(), f"generator/generator_epoch_{epoch}.pth")
        torch.save(discriminator.state_dict(), f"discriminator/discriminator_epoch_{epoch}.pth")
        torch.save(generator.state_dict(), f"generator/generator_final.pth")
        torch.save(discriminator.state_dict(), f"discriminator/discriminator_final.pth")
        torch.save({
            "epoch": epoch,
            "generator_state_dict": generator.state_dict(),
            "discriminator_state_dict": discriminator.state_dict(),
            "optimizer_g_state_dict": optim_g.state_dict(),
            "optimizer_d_state_dict": optim_d.state_dict(),
        }, "checkpoint/checkpoint.pth")
        print(f"ğŸ’¾ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ˆEpoch {epoch}ï¼‰")

